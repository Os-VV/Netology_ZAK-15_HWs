## Домашнее задание «Сохранение результатов эксперимента»

### Разведочный анализ данных и классификация качества вин.


### Описание датасета

Датасет содержит 6497 строк и 13 атрибутов: 'fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', and 'quality'. присутствуют пропущенные значения. Целевой атрибут 'quality' принимает 7 числовых значений от 3 до 9. Данные не сбалансированы, большинство вин имеют оценку качества 5, 6.
Скоррелированы признаки 'total sulfur dioxide' и 'free sulfur dioxide' (0.72); 'density' и 'alcohol' (-0.69).

### Предобработка данных

Перед построением модели применены методы предобработки данных: категориальные значения столбца 'type' преобразованы в числовые методом one-hot кодирования, пропущенные значения добавлены методом многовариантного восстановления (klearn.impute.IterativeImputer).

### Построение модели и оценка качества

В качестве базовой модели использовано дерево решений с базовыми настройками. Модель переобучилась: оценка на обучающих данных 1.0, на тестовых - 0.589. Отчет производительности показал, что модель в целом верно предсказывает классы, составляющие большинство в датасете (5 и 6). Слабо представленные классы предсказать не удалось. 

Использование случайного леса несколько улучшило результат (0.998 и 0.677 на обучающих и тестовых данных), но классы 3 и 9 не были предсказаны. 

Для решения проблемы с дисбалансом классов использован метод SMOTE, после применения которого оценка модели на тестовых данных увеличилась до 0.784

### Отбор признаков

Предпринята попытка избавиться от скореллированнах признаков 'total sulfur dioxide', 'density'. Результат на тесте - 0.781. Это подтверждает, что корреляция признаков слабо влияет на качество работы моделей, основанных на деревьях решений.

### Настройка гиперпараметров

При помощи рандомизированного поиска (RandomizedSearchCV) определены гиперпараметры, максимально влияющие на качество классификации. После чего предпринята попытка поиска оптимальных значений при помощи GridSearchCV.
Результат подбора неудовлетворительный: модель показала худший результат (0.731 на тесте).

### Заключение

Проведенный эксперимент демонстрирует сложности выбора признаков и настройки гиперпараметров для улучшения классификационной модели. Как RandomizedSearchCV, так и GridSearchCV не смогли улучшить производительность модели Random Forest. Это говорит о том, что исходная модель, построенная после применения SMOTE для устранения дисбаланса классов, уже достаточно надежна. В дальнейшей работе могут быть рассмотрены другие методы отбора признаков, различные типы классификационных моделей или различные методы обработки дисбаланса классов.
